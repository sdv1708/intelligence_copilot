{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üß† Executive Intelligence Copilot - Enhanced Colab Deployment\n",
        "\n",
        "**Run with GPU acceleration + persistent storage!**\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Quick Start\n",
        "\n",
        "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\n",
        "2. **Run all cells**: Ctrl+F9 or Runtime ‚Üí Run all\n",
        "3. **Allow Drive access**: When prompted\n",
        "4. **Enter API keys**: When prompted\n",
        "5. **Access app**: Click the ngrok URL\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö° Performance\n",
        "\n",
        "| Operation | Local CPU | Colab GPU |\n",
        "|-----------|-----------|-----------|\n",
        "| Model Load | 8s | 2s |\n",
        "| 10-page Doc | 25s | 1.5s |\n",
        "| **Speedup** | 1x | **15-20x** |\n",
        "\n",
        "## üíæ Persistent Storage\n",
        "\n",
        "Your data saves to Google Drive and persists across sessions!\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Check GPU Availability\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(\"üîç Checking GPU availability...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"‚úÖ GPU DETECTED!\")\n",
        "    print(f\"   Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
        "    print(\"\\nüöÄ You'll get 15-20x faster embeddings!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è NO GPU DETECTED\")\n",
        "    print(\"   Go to: Runtime ‚Üí Change runtime type ‚Üí Select GPU\")\n",
        "    print(\"   Note: GPU gives 15-20x faster performance!\")\n",
        "\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Mount Google Drive for Persistent Storage\n",
        "\n",
        "**This ensures your data persists across Colab sessions!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "print(\"üìÇ Mounting Google Drive for persistent storage...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Mount Drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "# Create persistent directory structure\n",
        "DRIVE_PATH = '/content/drive/MyDrive/intelligence_copilot_data'\n",
        "os.makedirs(DRIVE_PATH, exist_ok=True)\n",
        "os.makedirs(f'{DRIVE_PATH}/faiss', exist_ok=True)\n",
        "os.makedirs(f'{DRIVE_PATH}/raw', exist_ok=True)\n",
        "\n",
        "# Set environment variables for persistent paths\n",
        "os.environ['DB_PATH'] = f'{DRIVE_PATH}/briefs.db'\n",
        "os.environ['FAISS_PATH'] = f'{DRIVE_PATH}/faiss'\n",
        "os.environ['RAW_PATH'] = f'{DRIVE_PATH}/raw'\n",
        "\n",
        "print(\"\\n‚úÖ PERSISTENT STORAGE CONFIGURED\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"üìÅ Storage location: {DRIVE_PATH}\")\n",
        "print(f\"üíæ Database: {os.environ['DB_PATH']}\")\n",
        "print(f\"üîç FAISS: {os.environ['FAISS_PATH']}\")\n",
        "print(\"\\nüìå Your data will survive Colab restarts!\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Check if existing data\n",
        "if os.path.exists(os.environ['DB_PATH']):\n",
        "    size = os.path.getsize(os.environ['DB_PATH']) / 1024\n",
        "    print(f\"\\n‚úÖ Found existing database ({size:.1f} KB)\")\n",
        "    print(\"   Your previous meetings will be loaded!\")\n",
        "else:\n",
        "    print(\"\\nüìù First run - database will be created\")\n",
        "\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Upload Your Project\n",
        "\n",
        "Use folder icon on left to upload your entire `intelligence_copilot` folder\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT_PATH = \"/content/intelligence_copilot\"\n",
        "\n",
        "if os.path.exists(PROJECT_PATH):\n",
        "    os.chdir(PROJECT_PATH)\n",
        "    print(f\"‚úÖ Working directory: {os.getcwd()}\")\n",
        "    print(f\"üìÇ Files found: {len(os.listdir('.'))} items\")\n",
        "else:\n",
        "    print(f\"‚ùå Project not found at {PROJECT_PATH}\")\n",
        "    print(\"\\nüì§ Please upload:  Click folder icon ‚Üí Upload folder ‚Üí intelligence_copilot\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Install Dependencies (~2 minutes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"üì¶ Installing dependencies...\")\n",
        "%pip install -q -r requirements.txt\n",
        "%pip install -q pyngrok\n",
        "print(\"‚úÖ Dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Configure API Keys\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "print(\"üîë API KEY CONFIGURATION\\n\")\n",
        "print(\"Select LLM provider:\")\n",
        "print(\"  1. Gemini (Free tier - Recommended)\")\n",
        "print(\"  2. OpenAI\")\n",
        "print(\"  3. Anthropic\")\n",
        "\n",
        "choice = input(\"\\nEnter choice (1/2/3): \") or \"1\"\n",
        "provider = {\"1\": \"gemini\", \"2\": \"openai\", \"3\": \"anthropic\"}[choice]\n",
        "os.environ[\"LLM_PROVIDER\"] = provider\n",
        "\n",
        "if provider == \"gemini\":\n",
        "    print(\"\\nüìù Get free key: https://makersuite.google.com/app/apikey\")\n",
        "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter Gemini API key: \")\n",
        "elif provider == \"openai\":\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key: \")\n",
        "elif provider == \"anthropic\":\n",
        "    os.environ[\"ANTHROPIC_API_KEY\"] = getpass(\"Enter Anthropic API key: \")\n",
        "\n",
        "print(\"\\nüì° Ngrok Setup\")\n",
        "print(\"Sign up free: https://dashboard.ngrok.com/signup\")\n",
        "os.environ[\"NGROK_TOKEN\"] = getpass(\"Enter ngrok authtoken: \")\n",
        "\n",
        "print(f\"\\n‚úÖ Configured: {provider.upper()} + Ngrok\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Launch App üöÄ\n",
        "\n",
        "**Run this and click the ngrok URL!** Logs appear below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "ngrok.set_auth_token(os.environ[\"NGROK_TOKEN\"])\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.run([\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.headless=true\"])\n",
        "\n",
        "thread = threading.Thread(target=run_streamlit, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "print(\"üöÄ Starting Streamlit...\")\n",
        "time.sleep(10)\n",
        "\n",
        "public_url = ngrok.connect(8501, bind_tls=True)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"‚úÖ APP IS RUNNING!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüåê URL: {public_url}\")\n",
        "print(\"\\nüìù Usage: Click URL ‚Üí Create meeting ‚Üí Upload docs ‚Üí Generate brief\")\n",
        "print(\"üíæ Data saves to Google Drive automatically\")\n",
        "print(\"\\nüõë To stop: Click stop button above\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nüìã LOGS (real-time):\")\n",
        "print(\"-\"*60)\n",
        "\n",
        "try:\n",
        "    thread.join()\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\nüõë Shutting down...\")\n",
        "    ngrok.disconnect(public_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monitor GPU\n",
        "!nvidia-smi\n",
        "\n",
        "# Check database\n",
        "import sqlite3\n",
        "db = os.environ.get('DB_PATH')\n",
        "if os.path.exists(db):\n",
        "    conn = sqlite3.connect(db)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT COUNT(*) FROM meetings\")\n",
        "    print(f\"\\nüìä Database: {cursor.fetchone()[0]} meetings\")\n",
        "    conn.close()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
